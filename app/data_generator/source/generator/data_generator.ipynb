{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install treelib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treelib import Node, Tree\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_fd():    \n",
    "    global my_dict\n",
    "    my_dict = {\n",
    "        \"level1\": {\n",
    "            \"is_parent\": True,\n",
    "            \"number_of_distinct_vals\": 10,\n",
    "            \"total_vals\": 0,\n",
    "            \"dups\": 2,\n",
    "            \"number_of_dup_values\": 10\n",
    "            #,\n",
    "            #\"key_2\": \"test2\"\n",
    "        },\n",
    "        \"level2\": {\n",
    "            \"is_parent\": True,\n",
    "            \"number_of_distinct_vals\": 2,\n",
    "            \"total_vals\": 0,\n",
    "            \"dups\": 0,\n",
    "            \"number_of_dup_values\": 2\n",
    "            #,\n",
    "            #\"key_2\": \"test2\"\n",
    "        },\n",
    "        \"level3\": {\n",
    "            \"is_parent\": False,\n",
    "            \"number_of_distinct_vals\": 2,\n",
    "            \"total_vals\": 0, #number of distinct values * number of dups of last level,\n",
    "            \"dups\": 3,\n",
    "            \"number_of_dup_values\": 2\n",
    "            #,\n",
    "            #\"key_2\": \"test2\"\n",
    "        },\n",
    "        \"level4\": {\n",
    "            \"is_parent\": False,\n",
    "            \"number_of_distinct_vals\": 2,\n",
    "            \"total_vals\": 0,\n",
    "            \"dups\": 4,\n",
    "            \"number_of_dup_values\": 2\n",
    "            #,\n",
    "            #\"key_2\": \"test2\"\n",
    "        },\n",
    "        \"level5\": {\n",
    "            \"is_parent\": False,\n",
    "            \"number_of_distinct_vals\": 2,\n",
    "            \"total_vals\": 0,\n",
    "            \"dups\": 3,\n",
    "            \"number_of_dup_values\": 2\n",
    "            #,\n",
    "            #\"key_2\": \"test2\"\n",
    "        },\n",
    "        \"level6\": {\n",
    "            \"is_parent\": False,\n",
    "            \"number_of_distinct_vals\": 4,\n",
    "            \"total_vals\": 0,\n",
    "            \"dups\": 2,\n",
    "            \"number_of_dup_values\": 2\n",
    "            #,\n",
    "            #\"key_2\": \"test2\"\n",
    "        },\n",
    "        \"level7\": {\n",
    "            \"is_parent\": True,\n",
    "            \"number_of_distinct_vals\": 2,\n",
    "            \"total_vals\": 0,\n",
    "            \"dups\": 0,\n",
    "            \"number_of_dup_values\": 2\n",
    "            #,\n",
    "            #\"key_2\": \"test2\"\n",
    "        },\n",
    "        \"level8\": {\n",
    "            \"is_parent\": False,\n",
    "            \"number_of_distinct_vals\": 5,\n",
    "            \"total_vals\": 0,\n",
    "            \"dups\": 0,\n",
    "            \"number_of_dup_values\": 0\n",
    "            #,\n",
    "            #\"key_2\": \"test2\"\n",
    "        }\n",
    "    }\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_input(current_level=1,first_level=8,fd_dict={}):\n",
    "    v_add_up=1\n",
    "    v_distinct_values=2\n",
    "    if fd_dict[\"level\"+str(current_level)][\"is_parent\"]==False and fd_dict[\"level\"+str(current_level)][\"total_vals\"]==0 and current_level+1<=first_level:\n",
    "        v_add_up=v_add_up*fd_dict[\"level\"+str(current_level)][\"number_of_distinct_vals\"]*update_input(current_level+1,fd_dict=fd_dict)\n",
    "        fd_dict[\"level\"+str(current_level)][\"total_vals\"]=v_add_up\n",
    "        #if fd_dict[\"level\"+str(current_level+1)][\"is_parent\"]==True:\n",
    "        #    v_add_up=v_add_up*fd_dict[\"level\"+str(current_level)][\"dups\"]\n",
    "        #    fd_dict[\"level\"+str(current_level)][\"total_vals\"]=v_add_up\n",
    "        #else:\n",
    "        #    fd_dict[\"level\"+str(current_level)][\"total_vals\"]=v_add_up\n",
    "    elif fd_dict[\"level\"+str(current_level)][\"is_parent\"]==False and fd_dict[\"level\"+str(current_level)][\"total_vals\"]==0 and current_level+1>first_level:\n",
    "        fd_dict[\"level\"+str(current_level)][\"total_vals\"]=v_distinct_values\n",
    "    elif fd_dict[\"level\"+str(current_level)][\"is_parent\"]==True:\n",
    "        v_add_up=fd_dict[\"level\"+str(current_level)][\"number_of_distinct_vals\"]\n",
    "    return v_add_up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "set_fd() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-670-8432dc1b8686>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfirst_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmy_dict2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmy_dict2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset_fd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_dict2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfirst_level\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mupdate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfirst_level\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmy_dict2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: set_fd() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "first_level=8\n",
    "global my_dict={}\n",
    "set_fd()\n",
    "for i in range(1,first_level+1):\n",
    "    update_input(i,first_level,my_dict)\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_col_headers(new_file,first_level,letter):\n",
    "    with open(new_file, 'a+',newline=\"\") as f_out:\n",
    "        for i in range(1,first_level+1):\n",
    "            if first_level!=i:\n",
    "                f_out.write(chr(letter+first_level-i)+',')\n",
    "            else:\n",
    "                f_out.write(chr(letter+first_level-i)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "global my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(level=0,first_level=8,tree=Tree(),parent=\"\",parent_index=0,letter=65,num_of_dups=3,out_text=\"\",dup_sink_rate=1,start=1,end=3,FD_dict={},addup=0):\n",
    "    try:\n",
    "        if level!=0:\n",
    "            num_of_dups=my_dict[\"level\"+str(level)][\"dups\"]\n",
    "            is_parent=my_dict[\"level\"+str(level)][\"is_parent\"]  #it should be automatic (as input)\n",
    "            if my_dict[\"level\"+str(level)][\"dups\"]!=0:\n",
    "                dup_enabled=True\n",
    "            else:\n",
    "                dup_enabled=False #it should be automatic (as input)\n",
    "        #number_of_values=5 #it should be clacualted (according to some formula based on the total number of records)\n",
    "        v_letter=65\n",
    "        if level==first_level:\n",
    "            if is_parent==False:\n",
    "                num_of_distinct_vals=my_dict[\"level\"+str(level)][\"number_of_distinct_vals\"]\n",
    "                for i in range(1,num_of_distinct_vals+1):\n",
    "                #for i in range(1,3):\n",
    "                    tree.create_node(chr(letter)+str(i), out_text+chr(letter)+str(i),parent)\n",
    "                    new_file=\"C:\\\\Users\\TorabinejadM\\Desktop\\Thesis\\implementation\\\\data-generator\\\\data-generator\\\\source\\\\generator\\\\output\\\\tree.csv\"\n",
    "                    with open(new_file, 'a+',newline=\"\") as f_out:\n",
    "                        f_out.write(out_text+chr(letter)+str(i)+\"\\n\")\n",
    "            else:\n",
    "                for i in range(start,end):\n",
    "                    tree.create_node(chr(letter)+str(i),out_text+chr(letter)+str(i),parent)\n",
    "                    new_file=\".\\\\output\\\\tree.csv\"\n",
    "                    with open(new_file, 'a+',newline=\"\") as f_out:\n",
    "                        f_out.write(out_text+chr(letter)+str(i)+\"\\n\") \n",
    "        else:\n",
    "            if level!=0:\n",
    "                num_of_dups=my_dict[\"level\"+str(level)][\"dups\"]\n",
    "                is_parent=my_dict[\"level\"+str(level)][\"is_parent\"]  #it should be automatic (as input)\n",
    "                if my_dict[\"level\"+str(level)][\"dups\"]!=0:\n",
    "                    dup_enabled=True\n",
    "                else:\n",
    "                    dup_enabled=False #it should be automatic (as input)\n",
    "                if level==1:\n",
    "                    number_of_dup_values=my_dict[\"level\"+str(level)][\"number_of_dup_values\"] #it should be clacualted (according to some formula based on the total number of records)\n",
    "                    number_of_values=my_dict[\"level\"+str(level)][\"number_of_distinct_vals\"] #it should be clacualted (according to some formula based on the total number of records)\n",
    "                    for i in range(1,number_of_values+1):\n",
    "                        next_num_of_distinct_vals=my_dict[\"level\"+str(level+1)][\"number_of_distinct_vals\"]\n",
    "                        #start_point=(i-1)*next_num_of_distinct_vals+1\n",
    "                        #end_point=(i-1)*next_num_of_distinct_vals+next_num_of_distinct_vals+1\n",
    "                        if i>number_of_dup_values:\n",
    "                            start_point=(number_of_dup_values)*next_num_of_distinct_vals+(i-number_of_dup_values)\n",
    "                            end_point=(number_of_dup_values)*next_num_of_distinct_vals+(i-number_of_dup_values)+1\n",
    "                            #end_point=(i-1)*num_of_dups+2\n",
    "                        else:\n",
    "                            start_point=(i-1)*next_num_of_distinct_vals+1\n",
    "                            end_point=(i)*next_num_of_distinct_vals+1\n",
    "                            #end_point=(i-1)*num_of_dups+num_of_dups+1\n",
    "                        #if i>number_of_dup_values:\n",
    "                        #    end_point=(i-1)*num_of_dups+2\n",
    "                        #else:\n",
    "                        #    end_point=(i-1)*num_of_dups+num_of_dups+1\n",
    "                        out_text=out_text.replace(chr(letter)+str(i-1)+\",\",\"\")\n",
    "                        out_text=out_text+chr(letter)+str(i)+\",\"\n",
    "                        tree.create_node(chr(letter)+str(i),out_text,parent)\n",
    "                        generate_data(level+1,first_level,tree,parent=out_text,parent_index=i,letter=v_letter+first_level-level-1,num_of_dups=int(num_of_dups*dup_sink_rate),out_text=out_text,start=start_point,end=end_point)\n",
    "                else:\n",
    "                    if is_parent==False:\n",
    "                        #num_of_distinct_vals=num_of_dups\n",
    "                        num_of_distinct_vals=my_dict[\"level\"+str(level)][\"number_of_distinct_vals\"]\n",
    "                        next_num_of_distinct_vals=my_dict[\"level\"+str(level+1)][\"number_of_distinct_vals\"]\n",
    "                        number_of_dup_values=my_dict[\"level\"+str(level)][\"number_of_dup_values\"]\n",
    "                        for i in range(1,num_of_distinct_vals+1):\n",
    "                            v_addup=addup+(parent_index-1)*my_dict[\"level\"+str(level)][\"total_vals\"]\n",
    "                            if parent_index>1:\n",
    "                                zarib=parent_index-1\n",
    "                            else:\n",
    "                                zarib=0\n",
    "                            if i>number_of_dup_values:\n",
    "                            #if dup_enabled==False:\n",
    "                                start_point=v_addup+(number_of_dup_values)*next_num_of_distinct_vals+(i-number_of_dup_values)+zarib*(number_of_dup_values-num_of_distinct_vals)\n",
    "                                end_point=v_addup+(number_of_dup_values)*next_num_of_distinct_vals+(i-number_of_dup_values)+1+zarib*(number_of_dup_values-num_of_distinct_vals)\n",
    "                                #start_point=((i-1)*next_num_of_distinct_vals)+1\n",
    "                                #end_point=((i-1)*next_num_of_distinct_vals)+2\n",
    "                                #start_point=((i-1)*num_of_dups)+1\n",
    "                                #end_point=((i-1)*num_of_dups)+2\n",
    "                            else:\n",
    "                                start_point=v_addup+(i-1)*next_num_of_distinct_vals+1+zarib*(number_of_dup_values-num_of_distinct_vals)\n",
    "                                end_point=v_addup+i*next_num_of_distinct_vals+1+zarib*(number_of_dup_values-num_of_distinct_vals)\n",
    "                                #start_point=v_addup+(i-1)*num_of_dups+1\n",
    "                                #end_point=v_addup+i*num_of_dups+1\n",
    "                            out_text=out_text.replace(chr(letter)+str(i-1)+\",\",\"\")\n",
    "                            out_text=out_text+chr(letter)+str(i)+\",\"\n",
    "                            tree.create_node(chr(letter)+str(i),out_text,parent)\n",
    "                            generate_data(level+1,first_level,tree,parent=out_text,parent_index=i,letter=v_letter+first_level-level-1,num_of_dups=int(num_of_dups*dup_sink_rate),out_text=out_text,start=start_point,end=end_point,addup=v_addup)\n",
    "                    else:\n",
    "                        for i in range(start,end):\n",
    "                            num_of_distinct_vals=my_dict[\"level\"+str(level)][\"number_of_distinct_vals\"]\n",
    "                            next_num_of_distinct_vals=my_dict[\"level\"+str(level+1)][\"number_of_distinct_vals\"]\n",
    "                            number_of_dup_values=my_dict[\"level\"+str(level)][\"number_of_dup_values\"]\n",
    "                            if parent_index>1:\n",
    "                                zarib=parent_index-1\n",
    "                            else:\n",
    "                                zarib=0\n",
    "                            if i>number_of_dup_values:\n",
    "                                start_point=(number_of_dup_values)*next_num_of_distinct_vals+(i-number_of_dup_values)+zarib*(number_of_dup_values-num_of_distinct_vals)\n",
    "                                end_point=(number_of_dup_values)*next_num_of_distinct_vals+(i-number_of_dup_values)+1+zarib*(number_of_dup_values-num_of_distinct_vals)\n",
    "                            else:\n",
    "                                start_point=(i-1)*next_num_of_distinct_vals+1+zarib*(number_of_dup_values-num_of_distinct_vals)\n",
    "                                end_point=i*next_num_of_distinct_vals+1+zarib*(number_of_dup_values-num_of_distinct_vals)\n",
    "                            #if dup_enabled==False:\n",
    "                            #    start_point=((i-1)*num_of_dups)+1\n",
    "                            #    end_point=((i-1)*num_of_dups)+2\n",
    "                            #else:\n",
    "                            #    start_point=((i-1)*num_of_dups)+1\n",
    "                            #    end_point=((i-1)*num_of_dups)+num_of_dups+1\n",
    "                            out_text=out_text.replace(chr(letter)+str(i-1)+\",\",\"\")\n",
    "                            out_text=out_text+chr(letter)+str(i)+\",\"\n",
    "                            tree.create_node(chr(letter)+str(i),out_text,parent)\n",
    "                            generate_data(level+1,first_level,tree,parent=out_text,parent_index=i,letter=v_letter+first_level-level-1,num_of_dups=int(num_of_dups*dup_sink_rate),out_text=out_text,start=start_point,end=end_point,addup=0)\n",
    "            else:\n",
    "                try:\n",
    "                    os.remove(\"C:\\\\Users\\TorabinejadM\\Desktop\\Thesis\\implementation\\\\data-generator\\\\data-generator\\\\source\\\\generator\\\\output\\\\tree.csv\")\n",
    "                except FileNotFoundError:\n",
    "                    pass\n",
    "                new_file=\"C:\\\\Users\\TorabinejadM\\Desktop\\Thesis\\implementation\\\\data-generator\\\\data-generator\\\\source\\\\generator\\\\output\\\\tree.csv\"\n",
    "                set_col_headers(new_file,first_level,v_letter)\n",
    "                set_fd()\n",
    "                for i in range(1,first_level+1):\n",
    "                    update_input(i,first_level,my_dict)\n",
    "                tree.create_node(\"root\", \"root\")\n",
    "                generate_data(level+1,first_level,tree,parent=\"root\",letter=v_letter+first_level-level-1)\n",
    "        if level==0:\n",
    "            print(\"Done!\")\n",
    "            #print(tree.show())\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level=8\n",
    "for i in range(1,first_level+1):\n",
    "    update_input(i,first_level)\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"tree2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1\n",
      "test2\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"test1\")\n",
    "    try:\n",
    "        os.remove(\"tree.csv\")\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    print(\"test2\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
